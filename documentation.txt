DOCUMENTATION TEXT (summary of logic):
The solution is based on the DFS (depth first search) solution, but with a fork/join approach.
Same as the DFS, we start by placing the maze's initial node on a frontier stack, however as we progress through
the maze, when the algorithm finds multiple unvisited nodes, a "crossings", it will thereby spawn
new tasks (forks) to explore the these neighbours in parallell.
The new tasks inherit the current solver's own state (the visited set and current/predecssors map)
and will make it so that no previously visited node is explored again.
Each fork / subtask continues the search operation independenty. 
If we reach the goal the fork reassembles the path from where it began to the goal and returns this back to the "parent".
The parent task then will merge this partial parth with it's own segment to produce our path from
initial start node to goal.
In the single neighbour case we will not fork any new forks, in which the exploration continous in the current
thread. And if the algrorithm is exhausted with not finding the goal it will in this case return a null.
In short it only travels along valid nodes and edges, visits the nodes at most once per branch and ensures a 
parallel exploration where the multiple neighbours exists.

When it comes to abstract maps, if there are multiple goals it will return, the first path found.
If there are no goals, eventually there will not be any unvisited nodes remaining for new branches to explore. 
The algorithm then ends and returns null. 


Also, we avoid the explicit locks or semaphores by either copying or using thread-safe structures and therefore 
preventing race conditions.
The synchronizations occurs via the fork/join framewokr/library with fork() and join() methods.This makes sure the
solution doesn't have any locks, and using concurrency whenever the branching of the maze is large.
